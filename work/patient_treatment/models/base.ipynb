{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    df = df.copy()\n",
    "    #     Binary Encoding of gender\n",
    "    df[\"SEX\"] = df[\"SEX\"].replace({\"F\": 0, \"M\": 1})\n",
    "\n",
    "    return df\n",
    "\n",
    "def split_data(df):\n",
    "    # Splitting DF into X and y\n",
    "    y = df[\"SOURCE\"]\n",
    "    X = df.drop(\"SOURCE\", axis=1)\n",
    "\n",
    "    X_train, x_test, y_train, y_test = train_test_split(\n",
    "        X, y, train_size=0.7, shuffle=True, random_state=1\n",
    "    )\n",
    "\n",
    "    #    Scaling through Standard Scaler\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X_train)\n",
    "\n",
    "    X_train = pd.DataFrame(\n",
    "        sc.transform(X_train), columns=X_train.columns, index=X_train.index\n",
    "    )\n",
    "    x_test = pd.DataFrame(\n",
    "        sc.transform(x_test), columns=x_test.columns, index=x_test.index\n",
    "    )\n",
    "\n",
    "    return X_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/patient_treatment/data-ori.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessing(df)\n",
    "X_train, x_test, y_train, y_test = split_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"      Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"     Neural Network\": MLPClassifier(),\n",
    "    \"      Random Forest\": RandomForestClassifier(),\n",
    "    \"  Gradient Boosting\": GradientBoostingClassifier(),\n",
    "}\n",
    "\n",
    "for k, v in models.items():\n",
    "    v.fit(X_train, y_train)\n",
    "    print(k + \" Trained !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in models.items():\n",
    "    y_pred = v.predict(x_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(k + \" Accuracy : {:.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in models.items():\n",
    "    y_pred = v.predict(x_test)\n",
    "    f1 = f1_score(y_test, y_pred, pos_label=\"in\")\n",
    "    print(k + \" F1 score : {:.5f}\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize data\n",
    "y = df[main_label].values.reshape(\n",
    "    -1,\n",
    ")\n",
    "X = df.drop([main_label], axis=1)\n",
    "cat_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "cat_cols_idx = [list(X.columns).index(c) for c in cat_cols]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Pool\n",
    "train_pool = Pool(X_train, y_train, cat_features=cat_cols_idx)\n",
    "test_pool = Pool(X_test, y_test, cat_features=cat_cols_idx)\n",
    "# specify the training parameters\n",
    "model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    depth=5,\n",
    "    border_count=23,\n",
    "    l2_leaf_reg=0.3,\n",
    "    learning_rate=3e-3,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "# train the model\n",
    "model.fit(train_pool)\n",
    "# make the prediction using the resulting model\n",
    "y_train_pred = model.predict_proba(train_pool)[:, 1]\n",
    "y_test_pred = model.predict_proba(test_pool)[:, 1]\n",
    "roc_auc_train = roc_auc_score(y_train, y_train_pred)\n",
    "roc_auc_test = roc_auc_score(y_test, y_test_pred)\n",
    "print(\n",
    "    f\"ROC AUC score for train {round(roc_auc_train,4)}, and for test {round(roc_auc_test,4)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the baseline ROC AUC score assuming the same probability from training labels to test\n",
    "roc_auc_baseline = roc_auc_score(y_test, [np.mean(y_train)] * len(y_test))\n",
    "print(roc_auc_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapley values\n",
    "- Feature contribution to model's prediction\n",
    "- Interpretability: Providing clear insights to model behavior\n",
    "- Global & Local Explanations: They explain both overall feature importance (global) and individual predictions (local).\n",
    "- Model-Agnostic & Model-Specific Methods: SHAP can be applied to tree-based models, neural networks, and other ML algorithms.\n",
    "\n",
    "SHAP values come from Shapley values, which originate from cooperative game theory. The idea is to fairly distribute the total \"payout\" (model prediction) among the \"players\" (features) based on their contributions.\n",
    "\n",
    "### SHAP Value Formula\n",
    "\n",
    "For a given feature \\( i \\), its SHAP value is calculated as:\n",
    "\n",
    "$\n",
    "\\phi_i = \\sum_{S \\subseteq N \\setminus \\{i\\}} \\frac{|S|! (|N| - |S| - 1)!}{|N|!} \\left[ f(S \\cup \\{i\\}) - f(S) \\right]\n",
    "$\n",
    "\n",
    "where:\n",
    "- \\( N \\) is the set of all features.\n",
    "- \\( S \\) is a subset of features excluding \\( i \\).\n",
    "- \\( f(S) \\) is the model’s prediction when using only the features in \\( S \\).\n",
    "- \\( f(S \\cup \\{i\\}) \\) is the model’s prediction when adding feature \\( i \\) to subset \\( S \\).\n",
    "- The fraction is a weighting term ensuring fairness by averaging contributions over all possible subsets.\n",
    "\n",
    "### Example SHAP Calculation for a Feature (e.g., Size)\n",
    "\n",
    "For each subset \\( S \\), we compute:\n",
    "\n",
    "$\\Delta f = f(S \\cup \\{Size\\}) - f(S)$\n",
    "\n",
    "The SHAP value for \"Size\" is then:\n",
    "\n",
    "$\\phi_{Size} = \\frac{1}{3} (50K) + \\frac{1}{3} (50K) + \\frac{1}{6} (60K) + \\frac{1}{6} (60K)\n",
    "\n",
    "= 16.67K + 16.67K + 10K + 10K = 53.3K\n",
    "$\n",
    "\n",
    "Thus, the SHAP value for **Size** is **53.3K**, meaning \"Size\" contributes 53.3K to the final prediction.\n",
    "\n",
    "\n",
    "Cons: \n",
    "- The computation involves testing every possible combination of features, making it computationally expensive for large models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "ex = shap.TreeExplainer(model)\n",
    "print(f\"Average treatment probability is {round(np.mean(y_test),4)}\")\n",
    "shap_values = ex.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_test, max_display=30)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
